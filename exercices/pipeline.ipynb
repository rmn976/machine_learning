{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importer vos libs \n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import sklearn as sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/labeled_data.csv', sep=','); df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['hate_speech','offensive_language','neither','class','tweet']]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tweet'] = df['tweet'].apply(lambda tweet: re.sub('[^A-Za-z]+', ' ', tweet.lower()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>rt mayasolovely as a woman you shouldn t comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rt mleew boy dats cold tyga dwn bad for cuffi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rt urkindofbrand dawg rt sbaby life you ever ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>rt c g anderson viva based she look like a tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>rt shenikaroberts the shit you hear about me ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hate_speech  offensive_language  neither  class  \\\n",
       "0            0                   0        3      2   \n",
       "1            0                   3        0      1   \n",
       "2            0                   3        0      1   \n",
       "3            0                   2        1      1   \n",
       "4            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0   rt mayasolovely as a woman you shouldn t comp...  \n",
       "1   rt mleew boy dats cold tyga dwn bad for cuffi...  \n",
       "2   rt urkindofbrand dawg rt sbaby life you ever ...  \n",
       "3   rt c g anderson viva based she look like a tr...  \n",
       "4   rt shenikaroberts the shit you hear about me ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop-words in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (2018.7.23)\n"
     ]
    }
   ],
   "source": [
    "!pip install stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop-words          2018.7.23\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from stop_words import get_stop_words\n",
    "\n",
    "\n",
    "clf = make_pipeline(\n",
    "    TfidfVectorizer(stop_words=get_stop_words('en')),\n",
    "    OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
    ")\n",
    "\n",
    "clf = clf.fit(X=df['tweet'], y=df['class'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64256281, 0.14180581, 0.21563137])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I hate you, please die!\"\n",
    "clf.predict_proba([text])[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joblib              1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hatespeech.joblib.z']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "model_filename = \"hatespeech.joblib.z\"\n",
    "\n",
    "joblib.dump((clf), model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = joblib.load(\"hatespeech.joblib.z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01820455, 0.70288736, 0.27890809])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"I love, good life!\"\n",
    "clf1.predict_proba([text1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Downloading streamlit-0.80.0-py2.py3-none-any.whl (8.2 MB)\n",
      "Collecting blinker\n",
      "  Downloading blinker-1.4.tar.gz (111 kB)\n",
      "Collecting protobuf!=3.11,>=3.6.0\n",
      "  Downloading protobuf-3.15.8-cp37-cp37m-win_amd64.whl (904 kB)\n",
      "Requirement already satisfied: pandas>=0.21.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from streamlit) (1.2.3)\n",
      "Collecting requests\n",
      "  Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from streamlit) (20.8)\n",
      "Collecting click>=7.0\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting cachetools>=4.0\n",
      "  Downloading cachetools-4.2.1-py3-none-any.whl (12 kB)\n",
      "Collecting astor\n",
      "  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\n",
      "Collecting altair>=3.2.0\n",
      "  Downloading altair-4.1.0-py3-none-any.whl (727 kB)\n",
      "Collecting pydeck>=0.1.dev5\n",
      "  Downloading pydeck-0.6.2-py2.py3-none-any.whl (4.2 MB)\n",
      "Requirement already satisfied: tornado>=5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from streamlit) (6.1)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from streamlit) (2.8.1)\n",
      "Collecting base58\n",
      "  Downloading base58-2.1.0-py3-none-any.whl (5.6 kB)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from streamlit) (8.1.2)\n",
      "Collecting watchdog\n",
      "  Downloading watchdog-2.0.2-py3-none-win_amd64.whl (74 kB)\n",
      "Collecting pyarrow\n",
      "  Downloading pyarrow-3.0.0-cp37-cp37m-win_amd64.whl (12.6 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from streamlit) (1.19.5)\n",
      "Collecting tzlocal\n",
      "  Downloading tzlocal-2.1-py2.py3-none-any.whl (16 kB)\n",
      "Collecting validators\n",
      "  Downloading validators-0.18.2-py3-none-any.whl (19 kB)\n",
      "Collecting toml\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Collecting gitpython\n",
      "  Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\n",
      "Collecting toolz\n",
      "  Downloading toolz-0.11.1-py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from altair>=3.2.0->streamlit) (0.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from altair>=3.2.0->streamlit) (2.11.2)\n",
      "Requirement already satisfied: jsonschema in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from altair>=3.2.0->streamlit) (3.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pandas>=0.21.0->streamlit) (2021.1)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from protobuf!=3.11,>=3.6.0->streamlit) (1.15.0)\n",
      "Requirement already satisfied: traitlets>=4.3.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.0.5)\n",
      "Requirement already satisfied: ipykernel>=5.1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from pydeck>=0.1.dev5->streamlit) (5.4.2)\n",
      "Collecting ipywidgets>=7.0.0\n",
      "  Downloading ipywidgets-7.6.3-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: ipython>=5.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (7.19.0)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (6.1.7)\n",
      "Requirement already satisfied: backcall in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.18.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (3.0.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (47.1.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (2.7.3)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.7.5)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Downloading widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.0.0-py3-none-any.whl (243 kB)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (5.0.8)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.8.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jinja2->altair>=3.2.0->streamlit) (1.1.1)\n",
      "Requirement already satisfied: jupyter-core in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (4.7.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.2.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (3.3.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jsonschema->altair>=3.2.0->streamlit) (0.17.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel>=5.1.2->pydeck>=0.1.dev5->streamlit) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.1.6)\n",
      "Requirement already satisfied: Send2Trash in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (6.0.7)\n",
      "Requirement already satisfied: terminado>=0.8.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.2)\n",
      "Requirement already satisfied: argon2-cffi in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.1.0)\n",
      "Requirement already satisfied: prometheus-client in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.9.0)\n",
      "Requirement already satisfied: pyzmq>=17 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (20.0.0)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from jupyter-core->nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (300)\n",
      "Requirement already satisfied: pywinpty>=0.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from terminado>=0.8.3->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.7)\n",
      "Requirement already satisfied: cffi>=1.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.14.4)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (2.20)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
      "Collecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->jsonschema->altair>=3.2.0->streamlit) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from importlib-metadata->jsonschema->altair>=3.2.0->streamlit) (3.4.0)\n",
      "Requirement already satisfied: jupyterlab-pygments in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: defusedxml in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.6.0)\n",
      "Requirement already satisfied: bleach in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (3.2.1)\n",
      "Requirement already satisfied: testpath in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.4.4)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.8.4)\n",
      "Requirement already satisfied: async-generator in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (1.4.3)\n",
      "Requirement already satisfied: webencodings in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python37\\lib\\site-packages (from packaging->streamlit) (2.4.7)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.4-py2.py3-none-any.whl (153 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\n",
      "Collecting idna<3,>=2.5\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "Collecting chardet<5,>=3.0.2\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "Using legacy 'setup.py install' for blinker, since package 'wheel' is not installed.\n",
      "Installing collected packages: widgetsnbextension, smmap, jupyterlab-widgets, urllib3, toolz, ipywidgets, idna, gitdb, chardet, certifi, watchdog, validators, tzlocal, toml, requests, pydeck, pyarrow, protobuf, gitpython, click, cachetools, blinker, base58, astor, altair, streamlit\n",
      "    Running setup.py install for blinker: started\n",
      "    Running setup.py install for blinker: finished with status 'done'\n",
      "Successfully installed altair-4.1.0 astor-0.8.1 base58-2.1.0 blinker-1.4 cachetools-4.2.1 certifi-2020.12.5 chardet-4.0.0 click-7.1.2 gitdb-4.0.7 gitpython-3.1.14 idna-2.10 ipywidgets-7.6.3 jupyterlab-widgets-1.0.0 protobuf-3.15.8 pyarrow-3.0.0 pydeck-0.6.2 requests-2.25.1 smmap-4.0.0 streamlit-0.80.0 toml-0.10.2 toolz-0.11.1 tzlocal-2.1 urllib3-1.26.4 validators-0.18.2 watchdog-2.0.2 widgetsnbextension-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "streamlit           0.80.0\n"
     ]
    }
   ],
   "source": [
    "!pip list | grep streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ci-dessous, code fait tout seul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text_lc = \"\".join([word.lower() for word in text if word not in string.punctuation]) # remove puntuation\n",
    "    text_rc = re.sub('[0-9]+', '', text_lc)\n",
    "    #text = re.split('\\W+', text_rc)    # tokenization     \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24783 Number of tweets has 36456 words\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "countVectorizer = CountVectorizer(analyzer=clean_text) \n",
    "countVector = countVectorizer.fit_transform(df['tweet'])\n",
    "print('{} Number of tweets has {} words'.format(countVector.shape[0], countVector.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaaaand</th>\n",
       "      <th>aaadontplayy</th>\n",
       "      <th>aaahhhhh</th>\n",
       "      <th>aahahah</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaliyahhhm</th>\n",
       "      <th>aaliyahhlovee</th>\n",
       "      <th>...</th>\n",
       "      <th>zulu</th>\n",
       "      <th>zvckslvtr</th>\n",
       "      <th>zwaaad</th>\n",
       "      <th>zwengersierra</th>\n",
       "      <th>zwhite</th>\n",
       "      <th>zwithr</th>\n",
       "      <th>zzachbarness</th>\n",
       "      <th>zzzentropy</th>\n",
       "      <th>zzzquil</th>\n",
       "      <th>zzzzzz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36456 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      a  aa  aaaaaaaaand  aaadontplayy  aaahhhhh  aahahah  aaliyah  \\\n",
       "0  1  2   0            0             0         0        0        0   \n",
       "1  1  0   0            0             0         0        0        0   \n",
       "2  1  1   0            0             0         0        0        0   \n",
       "3  1  1   0            0             0         0        0        0   \n",
       "4  2  0   0            0             0         0        0        0   \n",
       "\n",
       "   aaliyahhhm  aaliyahhlovee  ...  zulu  zvckslvtr  zwaaad  zwengersierra  \\\n",
       "0           0              0  ...     0          0       0              0   \n",
       "1           0              0  ...     0          0       0              0   \n",
       "2           0              0  ...     0          0       0              0   \n",
       "3           0              0  ...     0          0       0              0   \n",
       "4           0              0  ...     0          0       0              0   \n",
       "\n",
       "   zwhite  zwithr  zzachbarness  zzzentropy  zzzquil  zzzzzz  \n",
       "0       0       0             0           0        0       0  \n",
       "1       0       0             0           0        0       0  \n",
       "2       0       0             0           0        0       0  \n",
       "3       0       0             0           0        0       0  \n",
       "4       0       0             0           0        0       0  \n",
       "\n",
       "[5 rows x 36456 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect_df = pd.DataFrame(countVector.toarray(), columns=countVectorizer.get_feature_names())\n",
    "count_vect_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df[['class']]\n",
    "y.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 3,\n",
       "        \"!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\"],\n",
       "       [0, 3, 0,\n",
       "        '!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!'],\n",
       "       [0, 3, 0,\n",
       "        '!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit'],\n",
       "       ...,\n",
       "       [0, 3, 0,\n",
       "        'young buck wanna eat!!.. dat nigguh like I aint fuckin dis up again'],\n",
       "       [0, 6, 0, 'youu got wild bitches tellin you lies'],\n",
       "       [0, 0, 3,\n",
       "        '~~Ruffled | Ntac Eileen Dahlia - Beautiful color combination of pink, orange, yellow &amp; white. A Coll http://t.co/H0dYEBvnZB']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns='class')\n",
    "X = df\n",
    "X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.score(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
